#!/bin/bash

if [ "$#" -ne 5 ]; then
	echo -e "
	Usage: [id2taxonomy-parallel] Provide a list of prot/nuc accession IDs and get a summary of the taxID associations

	id2taxonomy-parallel [INPUT] [OUTPUT] [DATABASE] [MAX_BATCH_SIZEi max=90,000] [N_CPU]

	Warning: Inputs must be in this exact order.

	1)[INPUT] input file in csv with accesions in first column  or list of accessions
	2)[OUTPUT] output file handle
	3)[DATABASE] ncbi database to search (efetch -h for options)
	4)[MAX_BATCH_SIZE] The maximum number of sequences to retrieve per job (max tested=90000)
	5)[N_CPU] Number of cpus to use

	New options are being made for the newer version!
	"
	exit 1
fi

input_file="$1"
output_file="$2"
n_cpus="$5"
db="$3"
max_batch_size="$4"
tmpdir="tmp"

if [ -e "$output_file" ]; then
	echo "Output file '$output_file' already exists. Cannot overwrite."
	exit 1
fi

total_lines=$(wc -l < "$input_file")
batch_size=$((total_lines / n_cpus))
if ((batch_size > max_batch_size)); then
	batch_size=$max_batch_size
fi

num_batches=$((total_lines / batch_size))
if ((total_lines % batch_size != 0)); then
	  num_batches=$((num_batches + 1))
  fi

echo "Processing $total_lines sequences with $n_cpus CPUs..."
echo "The files will be downloaded in $num_batches batches..."
echo "Number of sequences per run: $batch_size"

download_batch() {
	start_line=$1
	end_line=$2
	batch_no=$3
	input_file=$4
	db=$5
	tmpdir=$6
	
	echo "Processing batch #$3 ..."
	echo -e "Downloading sequences $start_line-$end_line \n"
	
	ids=$(cut -f1 -d "," ${input_file} | sed -n "${start_line},${end_line}p")
	esummary -id ${ids} -db ${db} | xtract -pattern DocumentSummary -element Caption,TaxId > ${tmpdir}/${batch_no}.tmp


}


export -f download_batch

# make a tmp directory to store all parallel tasks 
if [ ! -d "$tmpdir" ]; then
        mkdir "$tmpdir"
        echo -e "A $tmpdir directory has been created.\n"
else
	{
		rmdir $tmpdir
		mkdir "$tmpdir"
		echo -e "A $tmpdir directory has been created.\n"
	} || {
	echo "Directory $tmpdir already exists and is not empty. Cannot overwite."
        exit 1
}
fi


# Run parallel job
starts=$(seq 1 $batch_size $total_lines)
ends=$(seq $batch_size $batch_size $total_lines && echo $total_lines)
batchno=$(seq $num_batches)
parallel --link --jobs ${n_cpus} download_batch {1} {2} {3} {4} {5} {6} ::: $starts ::: $ends ::: $batchno ::: "$input_file" ::: "$db" ::: "$tmpdir"

# Concatenate all parallel job .faa outputs into one final output
echo "All files done! Merging files into $output_file"
cat ${tmpdir}/*.tmp > $output_file
rm -r ${tmpdir}
echo "Done!"
